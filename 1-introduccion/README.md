# Introducción al curso
Bienvenidos a mi parte del curso! Vamos a pasar unas cuantas semanas juntos mirando muchos temas relacionados con el mundo de data science, machine learning y inteligencia artificial.

## Quien soy yo?
Yo soy [Andreas](https://www.linkedin.com/in/andreas-lloyd/) - medio noruego, medio gales y un data scientist profesional desde hace 5 años. Empecé en el mundo de consultoria y luego me he ido al mundo de productos tecnológicos - primero en [Cabify](https://cabify.com/es), luego en [Jeff](https://jeff.com/) y ahora en [Lingokids](https://lingokids.com/).

He trabajado en una gran variedad de proyectos, generalmente orientados hacia consumidores finales (lo que se llama “B2C”), en ámbitos como optimización de precios, fraude, personalización de experiencia de usuario, campañas de fidelidad... 

Lo que más me gusta del mundo de data science es crear productos tecnológicos y crear impacto.

## Objetivos del curso
Mi objetivo principal es daros experiencia de como puede ser aplicar los temas teoricos en un problema real.

Todos los proyectos presentan problemas distintos, pero hay cosas en comun y es muy util ganar experiencia para ver como solventar estos problemas.

Más especificamente:

* Como acercarnos a resolver problemas de negocio con datos
* Entender a que nos referimos cuando hablamos del concepto de “datos” en problemas de data science y machine learning 
* Ver el proceso tipico de aprender sobre nuestro problema para conseguir formular el problema de negocio en un problema tecnico
* Entrenar y evaluar modelos
* Mejorar estos modelos de formas sencillas y complejas

## Qué esperamos conseguir
Los skills principales que esperamos ganar son:

* Analizar datos
* Entender datos y resultados en el contexto de un problema de negocio
* Programacion basica del mundo de data science
* Los procesos tipicos de un problema de ML


## Nuestro proyecto
Vamos a imaginar que trabajamos para una empresa que quiere crecer su base de usuarios (como todos!). Imaginamos tambien que hemos identificado Twitter como un fuente posible de usuarios y queremos explotarlo.

Hemos visto que la clave es la creación de contenidos buenos y compartirlo sobre tweets populares, pero relevantes a este contenido que hemos creado. Por ejemplo, si Obama habla sobre como el deporte afecta el desarrollo de niños - compartir un articulo que profundiza sobre el tema en los comentarios podria traernos muchos usuarios.

Ahi la empresa nos ha pedido ayudar en el esfuerzo - queremos entender que tipos de tweets van a ser populares?

Nos interesan diferentes tipos de tweets sobre diferentes temas. También nos interesa poder compartir nuestro contenido lo más rapido posible - pero estamos limitados por el tiempo que tardamos en crear este contenido bueno, asi que “spamear” no nos vale como estrategia!

Entonces nuestro trabajo es poder proporcionar inteligencia (de alguna forma) sobre que tweets podran llegar a ser “populares” y validos para nuestra estrategia.

* Algunas ideas iniciales de como hacer esto?
* Como diferenciaria nuestro intento de ayudar con este problema frente a otro tipo de perfil, por ejemplo alguien de marketing o de investigacion qualitativa (sociologia, user experience etc.)?
* Que datos nos pueden ayudar?
* Como sabremos que hemos conseguido hacer algo util? 

## Cómo vamos a hacer las clases
Quiero que sea todo bastante practico y si es posible, hecho por vosotros sin demasiado ayuda!

Dicho esto, he estructurado cada semana / par de semanas en tareas generales que tenemos que ir haciendo. Creare un notebook de “base” que ya incluira algunas cosas de la tarea, pero vamos a tratar de ir resolviendo la tarea durante la clase como un conjunto.

Un ejemplo seria “explorar los datos” - no hace falta que haga yo una exploracion enorme antes de la clase, porque podemos ver todo juntos y decidir que mirar - pero dejare trocitos de codigo que podemos utilizar para agilizar el proceso, o por ejemplo aspectos relevantes de los datos que debemos mirar.

Tambien menciono que es dificil cubrir todos los aspectos de data science, ML y AI en un unico dataset, asi que a veces vamos a introducir limitaciones a lo que podemos hacer simplemente para aprender que hacer un algunas situaciones (por ejemplo, no permitir entrenar un modelo con ciertas variables, etc.)

Sera importante tomar notas durante las clases - algo magico de los "notebooks" es que permiten mezclar markdown y codigo!

## Requisitos tecnicos
Vamos a hacer todo el curso en Python, generalmente explotando Jupyter notebooks en Jupyter lab. Yo siempre tiro de Jupyer lab pero una alternativa muy buena es [Google colab](https://colab.research.google.com/) - no hace falta instalar nada y el procesamiento esta en remoto, una ventaja muy grande!

En terminos de librerias, vamos a estar utilizando principalmente:

* Pandas (muchisimo!)
* Plotnine (bastante)
* Scikit-learn (bastante)
* Numpy (algo)

Aunque el objetivo del curso NO es aprender a programar ni nada de este estilo - es necesario saber algo y vamos a aprender mucho de estas tecnologias de paso.

### Por que no usamos R/Java/Stata/SPSS/Excel/Spark/Julia/C…?
La tecnologia no es lo importante. Python es muy comun en este mundo ya que es un lenguaje muy flexible - una ventaja enorme. Si prefieres usar otra cosa, adelante! R y Julia son muy buenas alternativas. Si alguien quiere utilizar R, puedo ayudar.